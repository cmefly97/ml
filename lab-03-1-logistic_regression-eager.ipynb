{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 05 Logistic Classification(Regression) - Eager Execution\n",
    "* Logistic Classfication은 True or False와 같은 Binary나 복수개의 다항 분류에 쓰입니다 (Bernoulli Distribution)\n",
    "\n",
    "### 기본 Library 선언 및 Tensorflow 버전 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 강의에 설명할 Data입니다\n",
    "* x_data가 2차원 배열이기에 2차원 공간에 표현하여 x1과 x2를 기준으로 y_data 0과 1로 구분하는 예제입니다\n",
    "* Logistic Classification 통해 보라색과 노란색 y_data(Label)을 구분해 보겠습니다.\n",
    "* Test 데이터는 붉은색의 위치와 같이 추론시 1의 값을 가지게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train = [[1., 2.],\n",
    "          [2., 3.],\n",
    "          [3., 1.],\n",
    "          [4., 3.],\n",
    "          [5., 3.],\n",
    "          [6., 2.]]\n",
    "y_train = [[0.],\n",
    "          [0.],\n",
    "          [0.],\n",
    "          [1.],\n",
    "          [1.],\n",
    "          [1.]]\n",
    "\n",
    "x_test = [[5.,2.]]\n",
    "y_test = [[1.]]\n",
    "\n",
    "\n",
    "x1 = [x[0] for x in x_train]\n",
    "x2 = [x[1] for x in x_train]\n",
    "\n",
    "colors = [int(y[0] % 3) for y in y_train]\n",
    "plt.scatter(x1,x2, c=colors , marker='^')\n",
    "plt.scatter(x_test[0][0],x_test[0][1], c=\"red\")\n",
    "\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Tensorflow Eager\n",
    "### 위 Data를 기준으로 가설의 검증을 통해 Logistic Classification 모델을 만들도록 하겠습니다\n",
    "* Tensorflow data API를 통해 학습시킬 값들을 담는다 (Batch Size는 한번에 학습시킬 Size로 정한다)\n",
    "* features,labels는 실재 학습에 쓰일 Data (연산을 위해 Type를 맞춰준다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(len(x_train))#.repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 위 Data를 기준으로 가설의 검증을 통해 Logistic Classification 모델을 만들도록 하겠습니다\n",
    "* W와 b은 학습을 통해 생성되는 모델에 쓰이는 Wegith와 Bias (초기값을 variable : 0이나 Random값으로 가능 tf.random_normal([2, 1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([2,1]), name='weight')\n",
    "b = tf.Variable(tf.zeros([1]), name='bias')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid 함수를 가설로 선언합니다\n",
    "* Sigmoid는 아래 그래프와 같이 0과 1의 값만을 리턴합니다 tf.sigmoid(tf.matmul(X, W) + b)와 같습니다\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "sigmoid(x) & = \\frac{1}{1+e^{-x}}  \\\\\\\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "![sigmoid](https://upload.wikimedia.org/wikipedia/commons/8/88/Logistic-curve.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(features):\n",
    "    hypothesis  = tf.div(1., 1. + tf.exp(tf.matmul(features, W) + b))\n",
    "    return hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가설을 검증할 Cost 함수를 정의합니다\n",
    "$$\n",
    "\\begin{align}\n",
    "cost(h(x),y) & = −log(h(x))  &  if  &  y=1 \\\\\\\\\\\n",
    "cost(h(x),y) & = -log(1−h(x))  &  if  &  y=0\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 위 두수식을 합치면 아래과 같습니다\n",
    "$$\n",
    "\\begin{align}\n",
    "cost(h(x),y) & = −y log(h(x))−(1−y)log(1−h(x))\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(hypothesis, features, labels):\n",
    "    cost = -tf.reduce_mean(labels * tf.log(logistic_regression(features)) + (1 - labels) * tf.log(1 - hypothesis))\n",
    "    return cost\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추론한 값은 0.5를 기준(Sigmoid 그래프 참조)로 0과 1의 값을 리턴합니다.\n",
    "* Sigmoid 함수를 통해 예측값이 0.5보다 크면 1을 반환하고 0.5보다 작으면 0으로 반환합니다.\n",
    "* 가설을 통해 실재 값과 비교한 정확도를 측정합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(hypothesis, labels):\n",
    "    predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, labels), dtype=tf.int32))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientTape를 통해 경사값을 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(hypothesis, features, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss_fn(logistic_regression(features),features,labels)\n",
    "    return tape.gradient(loss_value, [W,b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Eager모드에서 학습을 실행합니다.\n",
    "* 위의 Data를 Cost함수를 통해 학습시킨 후 모델을 생성합니다. \n",
    "* 새로운 Data를 통한 검증 수행 [5,2]의 Data로 테스트 수행 (그래프상 1이 나와야 정상입니다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py:532: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-7-6afa75b867be>:2: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Iter: 0, Loss: 0.6874\n",
      "Iter: 100, Loss: 0.5776\n",
      "Iter: 200, Loss: 0.5349\n",
      "Iter: 300, Loss: 0.5054\n",
      "Iter: 400, Loss: 0.4838\n",
      "Iter: 500, Loss: 0.4671\n",
      "Iter: 600, Loss: 0.4535\n",
      "Iter: 700, Loss: 0.4420\n",
      "Iter: 800, Loss: 0.4319\n",
      "Iter: 900, Loss: 0.4228\n",
      "Iter: 1000, Loss: 0.4144\n",
      "Testset Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1001\n",
    "\n",
    "for step in range(EPOCHS):\n",
    "    for features, labels  in iter(dataset):\n",
    "        grads = grad(logistic_regression(features), features, labels)\n",
    "        optimizer.apply_gradients(grads_and_vars=zip(grads,[W,b]))\n",
    "        if step % 100 == 0:\n",
    "            print(\"Iter: {}, Loss: {:.4f}\".format(step, loss_fn(logistic_regression(features),features,labels)))\n",
    "test_acc = accuracy_fn(logistic_regression(x_test),y_test)\n",
    "print(\"Testset Accuracy: {:.4f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
